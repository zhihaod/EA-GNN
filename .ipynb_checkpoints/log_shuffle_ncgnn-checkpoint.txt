datasaet: cora,  model: ncgnn.
time of construct data:0.25305795669555664
epoch: 0, val_loss: 1.8005341291427612
epoch: 1, val_loss: 1.6993754506111145
epoch: 2, val_loss: 1.5936369895935059
epoch: 3, val_loss: 1.477461814880371
epoch: 4, val_loss: 1.3659517765045166
epoch: 5, val_loss: 1.264578640460968
epoch: 6, val_loss: 1.176044225692749
epoch: 7, val_loss: 1.100545883178711
epoch: 8, val_loss: 1.0418742299079895
epoch: 9, val_loss: 0.994686096906662
epoch: 10, val_loss: 0.9564619958400726
epoch: 11, val_loss: 0.9301034212112427
epoch: 12, val_loss: 0.9101968705654144
epoch: 13, val_loss: 0.900494784116745
epoch: 14, val_loss: 0.8896198272705078
epoch: 15, val_loss: 0.8821212947368622
epoch: 16, val_loss: 0.8765222430229187
epoch: 17, val_loss: 0.8773662745952606
epoch: 18, val_loss: 0.8765794336795807
epoch: 19, val_loss: 0.8817846775054932
epoch: 20, val_loss: 0.8844626843929291
epoch: 21, val_loss: 0.8881026804447174
Final epoch: 21
beta:0.6,accuracy:0.669921875

epoch: 0, val_loss: 1.810329020023346
epoch: 1, val_loss: 1.7001498937606812
epoch: 2, val_loss: 1.5906813740730286
epoch: 3, val_loss: 1.4722298383712769
epoch: 4, val_loss: 1.3516627550125122
epoch: 5, val_loss: 1.2416764497756958
epoch: 6, val_loss: 1.1464835405349731
epoch: 7, val_loss: 1.0659837126731873
epoch: 8, val_loss: 0.9994694292545319
epoch: 9, val_loss: 0.9452096819877625
epoch: 10, val_loss: 0.9037523865699768
epoch: 11, val_loss: 0.8757815062999725
epoch: 12, val_loss: 0.8534544110298157
epoch: 13, val_loss: 0.8352397978305817
epoch: 14, val_loss: 0.8197050392627716
epoch: 15, val_loss: 0.812828004360199
epoch: 16, val_loss: 0.8086310625076294
epoch: 17, val_loss: 0.8037478625774384
epoch: 18, val_loss: 0.8026845157146454
epoch: 19, val_loss: 0.8053794205188751
epoch: 20, val_loss: 0.8045703768730164
epoch: 21, val_loss: 0.8049172461032867
epoch: 22, val_loss: 0.8092384338378906
epoch: 23, val_loss: 0.8124239444732666
Final epoch: 23
time of one train:4.769425868988037
beta:0.8,accuracy:0.697265625

epoch: 0, val_loss: 1.8131733536720276
epoch: 1, val_loss: 1.6900609731674194
epoch: 2, val_loss: 1.567924439907074
epoch: 3, val_loss: 1.432922124862671
epoch: 4, val_loss: 1.2970449924468994
epoch: 5, val_loss: 1.1756137609481812
epoch: 6, val_loss: 1.075225055217743
epoch: 7, val_loss: 0.9925358593463898
epoch: 8, val_loss: 0.9246423542499542
epoch: 9, val_loss: 0.8728923499584198
epoch: 10, val_loss: 0.837554931640625
epoch: 11, val_loss: 0.8093909919261932
epoch: 12, val_loss: 0.7844763994216919
epoch: 13, val_loss: 0.769960880279541
epoch: 14, val_loss: 0.762473076581955
epoch: 15, val_loss: 0.7527501583099365
epoch: 16, val_loss: 0.7460004389286041
epoch: 17, val_loss: 0.7445218861103058
epoch: 18, val_loss: 0.7425270676612854
epoch: 19, val_loss: 0.7441077828407288
epoch: 20, val_loss: 0.7452490925788879
epoch: 21, val_loss: 0.7475468218326569
epoch: 22, val_loss: 0.7501542568206787
epoch: 23, val_loss: 0.7545110285282135
Final epoch: 23
time of one train:4.884860038757324
beta:1.0,accuracy:0.728515625

epoch: 0, val_loss: 1.8066810965538025
epoch: 1, val_loss: 1.6781533360481262
epoch: 2, val_loss: 1.5482906699180603
epoch: 3, val_loss: 1.4087399244308472
epoch: 4, val_loss: 1.2677295804023743
epoch: 5, val_loss: 1.1431899666786194
epoch: 6, val_loss: 1.0374467968940735
epoch: 7, val_loss: 0.9527478516101837
epoch: 8, val_loss: 0.8867679834365845
epoch: 9, val_loss: 0.8366583585739136
epoch: 10, val_loss: 0.7991359829902649
epoch: 11, val_loss: 0.7680991590023041
epoch: 12, val_loss: 0.745928555727005
epoch: 13, val_loss: 0.7292394042015076
epoch: 14, val_loss: 0.7151512205600739
epoch: 15, val_loss: 0.7055745124816895
epoch: 16, val_loss: 0.7019309997558594
epoch: 17, val_loss: 0.6987969875335693
epoch: 18, val_loss: 0.6980070173740387
epoch: 19, val_loss: 0.6948437094688416
epoch: 20, val_loss: 0.6935358643531799
epoch: 21, val_loss: 0.6952857077121735
epoch: 22, val_loss: 0.7004571259021759
epoch: 23, val_loss: 0.7029215097427368
epoch: 24, val_loss: 0.7042495906352997
epoch: 25, val_loss: 0.7080851793289185
Final epoch: 25
time of one train:5.17798376083374
beta:1.2,accuracy:0.759765625

epoch: 0, val_loss: 1.7928075194358826
epoch: 1, val_loss: 1.6635668873786926
epoch: 2, val_loss: 1.5327510237693787
epoch: 3, val_loss: 1.3900107741355896
epoch: 4, val_loss: 1.2480247616767883
epoch: 5, val_loss: 1.1246777176856995
epoch: 6, val_loss: 1.0228350758552551
epoch: 7, val_loss: 0.9409697353839874
epoch: 8, val_loss: 0.8721853196620941
epoch: 9, val_loss: 0.8183020949363708
epoch: 10, val_loss: 0.7806341350078583
epoch: 11, val_loss: 0.7500415444374084
epoch: 12, val_loss: 0.7284229695796967
epoch: 13, val_loss: 0.7124436795711517
epoch: 14, val_loss: 0.6992144584655762
epoch: 15, val_loss: 0.6922367215156555
epoch: 16, val_loss: 0.6884324550628662
epoch: 17, val_loss: 0.6798614859580994
epoch: 18, val_loss: 0.6759843230247498
epoch: 19, val_loss: 0.6781691610813141
epoch: 20, val_loss: 0.6789870858192444
epoch: 21, val_loss: 0.6781240105628967
epoch: 22, val_loss: 0.6803971230983734
epoch: 23, val_loss: 0.6816112101078033
Final epoch: 23
time of one train:5.693108797073364
beta:1.4,accuracy:0.767578125

epoch: 0, val_loss: 1.7945265173912048
epoch: 1, val_loss: 1.6736391186714172
epoch: 2, val_loss: 1.554951548576355
epoch: 3, val_loss: 1.4217762351036072
epoch: 4, val_loss: 1.27785724401474
epoch: 5, val_loss: 1.1451777219772339
epoch: 6, val_loss: 1.0307365655899048
epoch: 7, val_loss: 0.938023030757904
epoch: 8, val_loss: 0.8643063008785248
epoch: 9, val_loss: 0.8088152408599854
epoch: 10, val_loss: 0.7676425576210022
epoch: 11, val_loss: 0.7426380515098572
epoch: 12, val_loss: 0.7226325571537018
epoch: 13, val_loss: 0.7029995620250702
epoch: 14, val_loss: 0.6917948424816132
epoch: 15, val_loss: 0.6826856136322021
epoch: 16, val_loss: 0.6767586469650269
epoch: 17, val_loss: 0.6713757216930389
epoch: 18, val_loss: 0.6690819263458252
epoch: 19, val_loss: 0.6678860783576965
epoch: 20, val_loss: 0.666491836309433
epoch: 21, val_loss: 0.6679252982139587
epoch: 22, val_loss: 0.6695926487445831
epoch: 23, val_loss: 0.6725176870822906
epoch: 24, val_loss: 0.6730198264122009
epoch: 25, val_loss: 0.6738359034061432
Final epoch: 25
time of one train:5.1584272384643555
beta:1.5999999999999999,accuracy:0.755859375

epoch: 0, val_loss: 1.7882561087608337
epoch: 1, val_loss: 1.658761203289032
epoch: 2, val_loss: 1.531480312347412
epoch: 3, val_loss: 1.3948079347610474
epoch: 4, val_loss: 1.2585945129394531
epoch: 5, val_loss: 1.136103332042694
epoch: 6, val_loss: 1.0329548716545105
epoch: 7, val_loss: 0.9483484625816345
epoch: 8, val_loss: 0.8819341063499451
epoch: 9, val_loss: 0.830505907535553
epoch: 10, val_loss: 0.7907152473926544
epoch: 11, val_loss: 0.7615658044815063
epoch: 12, val_loss: 0.7424037456512451
epoch: 13, val_loss: 0.7268592417240143
epoch: 14, val_loss: 0.7114621698856354
epoch: 15, val_loss: 0.7021915316581726
epoch: 16, val_loss: 0.6976548433303833
epoch: 17, val_loss: 0.6942982375621796
epoch: 18, val_loss: 0.69016894698143
epoch: 19, val_loss: 0.6854616701602936
epoch: 20, val_loss: 0.6833948493003845
epoch: 21, val_loss: 0.6832059323787689
epoch: 22, val_loss: 0.6888139843940735
epoch: 23, val_loss: 0.6886557936668396
epoch: 24, val_loss: 0.6870182454586029
epoch: 25, val_loss: 0.6866976916790009
epoch: 26, val_loss: 0.6885555684566498
Final epoch: 26
time of one train:5.39203405380249
beta:1.7999999999999998,accuracy:0.76953125

epoch: 0, val_loss: 1.8187456727027893
epoch: 1, val_loss: 1.6904094815254211
epoch: 2, val_loss: 1.5594677329063416
epoch: 3, val_loss: 1.4206076264381409
epoch: 4, val_loss: 1.2775494456291199
epoch: 5, val_loss: 1.144906222820282
epoch: 6, val_loss: 1.0307570695877075
epoch: 7, val_loss: 0.9418928921222687
epoch: 8, val_loss: 0.8726702034473419
epoch: 9, val_loss: 0.8206071555614471
epoch: 10, val_loss: 0.7794168591499329
epoch: 11, val_loss: 0.7486541867256165
epoch: 12, val_loss: 0.7295117974281311
epoch: 13, val_loss: 0.7164121866226196
epoch: 14, val_loss: 0.7042647004127502
epoch: 15, val_loss: 0.6919165551662445
epoch: 16, val_loss: 0.6835526823997498
epoch: 17, val_loss: 0.6784049272537231
epoch: 18, val_loss: 0.6758016049861908